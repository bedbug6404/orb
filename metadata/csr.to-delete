    function obj=import_calpar(obj,dataname,varargin)
      % parse mandatory arguments
      p=inputParser;
      p.addRequired('dataname', @(i) isa(i,'datanames'));
      p.parse(dataname);
      %retrieve product info
      product=obj.mdget(dataname);
      %check if data is already in matlab format
      if ~product.isfile('data')
        %get names of parameters and levels
        levels    =product.mdget('levels');
        fields    =product.mdget('fields');
        sats      =product.mdget('sats');
        bias_files=product.mdget('bias_files');
        %need to get long-term biases
        for s=1:numel(sats)
          ltb.(sats{s})=flipud(transpose(dlmread(bias_files{s})));
        end
        %load data
        for i=1:numel(levels)
          for j=1:numel(fields)
            tmp=struct('A',[],'B',[]);
            %read data
            for s=1:numel(sats)
              f=fullfile(product.mdget('import_dir'),['gr',sats{s},'.',fields{j},'.',levels{i},'.GraceAccCal']);
              tmp.(sats{s})=simpletimeseries.import(f,'cut24hrs',false);
              %enforce the long-term biases
              switch fields{j}
              case 'AC0X'
                lbt_idx=2;
              case {'AC0Y1','AC0Y2','AC0Y3','AC0Y4','AC0Y5','AC0Y6','AC0Y7','AC0Y8'}
                lbt_idx=3;
              case 'AC0Z'
                lbt_idx=4;
              otherwise
                lbt_idx=0;
              end
              if lbt_idx>0
                t=tmp.(sats{s}).mjd-ltb.(sats{s})(2,1);
                tmp.(sats{s})=tmp.(sats{s}).assign(...
                  [tmp.(sats{s}).y(:,1)+polyval(ltb.(sats{s})(:,lbt_idx),t),tmp.(sats{s}).y(:,2:end)]...
                );
              end
              
              %additional processing: add end of arcs
              switch levels{i}
                case {'aak','accatt'}
                %get arc starts
                arc_starts=tmp.(sats{s}).t;
                %build arc ends
                arc_ends=[arc_starts(2:end);dateshift(arc_starts(end),'end','day')]-seconds(1);
                %arc ends are at maximum 24 hours after arc starts
                fix_idx=arc_ends-arc_starts>days(1);
                arc_ends(fix_idx)=arc_starts(fix_idx)+days(1);
              case 'estim'
                %get arc starts
                arc_starts=tmp.(sats{s}).t;
                %build arc ends
                arc_ends=arc_starts+seconds(tmp.(sats{s}).y(:,3));
                %get seconds-of-day of arc ends
                sod_arc_ends=seconds(arc_ends-dateshift(arc_ends,'start','day'));
                %find the 24hrs arcs (those that have ~0 seconds of days)
                idx=find(sod_arc_ends<tmp.(sats{s}).t_tol);
                %push those arcs to mid-night and remove 1 second
                arc_ends(idx)=dateshift(arc_ends(idx),'start','day')-seconds(1);
              end
              
              %fancy stuff: handle parameters defined as arc segments
              if isempty(strfind(fields{j},'AC0Y'))
                %no fancy stuff, just propagate data
                y=tmp.(sats{s}).y;
              else
                %there are 8 segments per day
                periodicity=days(1)/8;
                %get day location for this parameter
                day_loc=double(fields{j}(5));
                %get sub-arc starts/ends
                sub_arc_starts=arc_starts+periodicity*(day_loc-1);
                  sub_arc_ends=arc_starts+periodicity*(day_loc  )-seconds(1);
                %cap sub-arc start/ends to be within the current arc
                sub_arc_starts=min([sub_arc_starts,arc_ends],[],2);
                  sub_arc_ends=min([sub_arc_ends,  arc_ends],[],2);
                %get only existing sub-arcs
                good_idx=sub_arc_starts<sub_arc_ends;
                %propagate data
                arc_starts=sub_arc_starts(good_idx);
                  arc_ends=sub_arc_ends(  good_idx);
                y=tmp.(sats{s}).y(good_idx,:);
              end
              
              %build timeseries with arc starts
              arc_start_ts=simpletimeseries(arc_starts,y,...
                'format','datetime',...
                'labels',tmp.(sats{s}).labels,...
                'units',tmp.(sats{s}).y_units,...
                'timesystem',tmp.(sats{s}).timesystem,...
                'descriptor',['start of arcs for ',tmp.(sats{s}).descriptor]...
              );
              %build timeseries with arc ends
              arc_end_ts=simpletimeseries(arc_ends,y,...
                'format','datetime',...
                'labels',tmp.(sats{s}).labels,...
                'units',tmp.(sats{s}).y_units,...
                'timesystem',tmp.(sats{s}).timesystem,...
                'descriptor',['end of arcs for ',tmp.(sats{s}).descriptor]...
              );
              %augment the start-of-arcs timeseries with the end-of-arcs (only new data)
              tmp.(sats{s})=arc_start_ts.augment(arc_end_ts,true);
              
              %additional processing: add gaps
              gap_idx=diff(tmp.(sats{s}).t)>seconds(1) & diff(tmp.(sats{s}).y(:,1))~=0;
              gap_t=tmp.(sats{s}).t(gap_idx)+seconds(1);
              %build timeseries with arc ends
              gap_ts=simpletimeseries(gap_t,nan(numel(gap_t),tmp.(sats{s}).width),...
                'format','datetime',...
                'labels',tmp.(sats{s}).labels,...
                'units',tmp.(sats{s}).y_units,...
                'timesystem',tmp.(sats{s}).timesystem,...
                'descriptor',['gaps for ',tmp.(sats{s}).descriptor]...
              );
              %augment the original timeseries with the gaps (only new data)
              tmp.(sats{s})=tmp.(sats{s}).augment(gap_ts,true);
            end
            
%             %ensure date is compatible between the satellites
%             if ~tmp.A.isteq(tmp.B)
%               [tmp.A,tmp.B]=tmp.A.merge(tmp.B);
%             end
            %propagate data to object
            for s=1:numel(sats)
              obj=obj.sat_set(product.dataname.type,levels{i},fields{j},sats{s},tmp.(sats{s}));
            end
            disp(str.tablify([15,6,3,6],'loaded data for',levels{i},'and',fields{j}))
          end
        end
%         %for each sat, ensure consistent time domain 
%         for s=1:numel(sats)
%           %gather names for this sat and level
%           names=obj.vector_names(product.dataname.type,'','',sats{s});
%           %gather info for user feedback
%           length_start=cellfun(@(i)(obj.data_get(i).length),names);
%           %ensure the time domain is the same for all fields (in each sat and level)
%           obj=obj.vector_op(@simpledata.merge_multiple,...
%             names,...
%             str.tablify([7,6,10],['GRACE-',sats{s}],levels{i},product.dataname.type)...
%           );
%           %user feedback
%           length_stop=cellfun(@(i)(obj.data_get(i).length),names);
%           cellfun(...
%             @(i,j,k)(disp(str.tablify([32,6,24,4],i.name,j,'data entries, changed by',k))),...
%             names,num2cell(length_start),num2cell(length_stop-length_start))
%         end
        %loop over all sat and level to check Job IDs agreement
        for i=1:numel(levels)
          for s=1:numel(sats)
            %gather names for this sat and level
            names=obj.vector_names(product.dataname.type,levels{i},'',sats{s});
            %ensure job IDs are consistent for all fields (in each sat and level)
            equal_idx=obj.vector_tr(@simpledata.isequal_multiple,...
              names,...
              product.mdget('jobid_col'),...
              str.tablify([7,6,10],['GRACE-',sats{s}],levels{i},product.dataname.type)...
            );
            for j=1:numel(equal_idx)
              if ~equal_idx{j}
                error([mfilename,': Job ID inconsistency between ',...
                  '[',strjoin(names{j  },','),'] and ',...
                  '[',strjoin(names{j+1},','),']  (possibly more).'])
              end
            end
          end
        end
%         %loop over all sat, add epochs at day boundaries and build fstep time domain
%         for i=1:numel(levels)
%           for j=1:numel(fields)
%             for s=1:numel(sats)
%               %save time series into dedicated var
%               ts_now=obj.sat_get(product.dataname.type,levels{i},fields{j},sats{s});
%               %create epochs at day boundaries
%               t_days=dateshift(ts_now.t(1),'start','day'):days(1):dateshift(ts_now.t(end),'end','day');
%               %add day boundaries
%               ts_now=ts_now.t_merge(t_days);
%               %build fstep time domain
%               ts_now=ts_now.fstep(seconds(1));
%               %save time series back to object
%               obj=obj.sat_set(product.dataname.type,levels{i},fields{j},sats{s},ts_now);
%             end
%           end
%         end

        %loop over all sats, levels and fields to:
        % - in case of estim: ensure that there are no arcs with lenghts longer than consecutive time stamps
        % - in case of aak and accatt: ensure that the t0 value is the same as the start of the arc
        for s=1:numel(sats)
          %loop over all required levels
          for i=1:numel(levels)
            switch levels{i}
            case 'estim'
              %this check ensures that there are no arcs with lenghts longer than consecutive time stamps
              for j=1:numel(fields)
                disp(str.tablify([8,10,6,6,1],'Checking',product.dataname.type,levels{i},fields{j},sats{s}))
                %save time series into dedicated var
                ts_now=obj.sat_get(product.dataname.type,levels{i},fields{j},sats{s});
                %forget about epochs that have been artificially inserted to represent gaps and end of arcs
                idx1=find(diff(ts_now.t)>seconds(1));
                %get arc lenths
                al=ts_now.y(idx1,3);
                %get consecutive time difference
                dt=seconds(diff(ts_now.t(idx1)));
                %find arcs that span over time stamps
                bad_idx=find(al(1:end-1)-dt>ts_now.t_tol); %no abs here!
                %report if any such epochs have been found
                if ~isempty(bad_idx)
                  msg=cell(1,min([numel(bad_idx),10])+1);
                  msg{1}='idx: arc init time; arc length; succ time diff; delta arc len (should be zero)';
                  for k=1:numel(msg)-1
                    idx=idx1(bad_idx(k));
                    msg{k+1}=[...
                      num2str(idx1(bad_idx(k))),': ',...
                      datestr(ts_now.t(idx)),'; ',...
                      num2str(al(bad_idx(k)),'%.5d'),'; ',...
                      num2str(dt(bad_idx(k))),' ',...
                      num2str(al(bad_idx(k))-dt(bad_idx(k)))...
                    ];
                  end
                  disp([....
                    ': found ',num2str(numel(bad_idx)),' arc lengths (3rd column) longer than ',...
                    ' difference between consecutive time stamps (4th column):',10,...
                    strjoin(msg,'\n'),10,...
                    'These data have been discarded!'
                  ])
                  mask=ts_now.mask;
                  mask(idx1(bad_idx))=false;
                  obj=obj.sat_set(product.dataname.type,levels{i},fields{j},sats{s},ts_now.mask_and(mask).mask_update);
                end
              end
            case {'aak','accatt'}
              %this check ensures that the t0 value is the same as the start of the arc
              for j=1:numel(fields)
                %some fields do not have t0
                if ~any(fields{j}(end)=='DQ')
                  disp(str.tablify([8,10,6,6,1],'Skipping',product.dataname.type,levels{i},fields{j},sats{s}))
                  continue
                end
                disp(str.tablify([8,10,6,6,1],'Checking',product.dataname.type,levels{i},fields{j},sats{s}))
                %save time series into dedicated var
                ts_now=obj.sat_get(product.dataname.type,levels{i},fields{j},sats{s});
                %forget about epochs that have been artificially inserted to represent forward steps
                idx1=find(diff(ts_now.t)>seconds(1));
                %get t0
                t0=simpletimeseries.utc2gps(datetime(ts_now.y(idx1,3),'convertfrom','modifiedjuliandate'));
                %find arcs that have (much) t0 different than their first epoch
                bad_idx=find(abs(ts_now.t(idx1)-t0)>seconds(1) & ts_now.mask(idx1));
                %report if any such epochs have been found
                if ~isempty(bad_idx)
                  msg=cell(1,min([numel(bad_idx),10])+1);
                  msg{1}='idx: arc init time - MJD = delta time (should be zero)';
                  for k=1:numel(msg)-1
                    idx=idx1(bad_idx(k));
                    msg{k+1}=[...
                      num2str(idx1(bad_idx(k))),': ',...
                      datestr(ts_now.t(idx1(bad_idx(k))),'yyyy-mm-dd HH:MM:SS'),' - ',...
                      datestr(t0(bad_idx(k)),'yyyy-mm-dd HH:MM:SS'),' = ',...
                      char(ts_now.t(idx1(bad_idx(k)))-t0(bad_idx(k)))...
                    ];
                  end
                  disp([...
                    'found ',num2str(numel(bad_idx)),' arc init time (2nd column) different than the',...
                    ' MJD reported in the data (3rd column):',10,...
                    strjoin(msg,'\n'),10,...
                    'These data have been discarded!'
                  ])
                  mask=ts_now.mask;
                  mask(idx1(bad_idx))=false;
                  obj=obj.sat_set(product.dataname.type,levels{i},fields{j},sats{s},ts_now.mask_and(mask).mask_update);
                end
              end
            end
          end
        end
        %save data
        s=obj.datatype_get(product.dataname.type); %#ok<*NASGU>
        save(char(product.file('data')),'s');
        clear s
      else
        %load data
        load(char(product.file('data')),'s');
        levels=fieldnames(s); %#ok<NODEF>
        for i=1:numel(levels)
          obj=obj.level_set(product.dataname.type,levels{i},s.(levels{i}));
        end
      end
    end